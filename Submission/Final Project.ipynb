{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10eff7e",
   "metadata": {},
   "source": [
    "# First Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e020cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session Initialization\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Depression_Prediction_Project\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e652f0a",
   "metadata": {},
   "source": [
    "# Part 1 - Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, isnan, when, count, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, ChiSqSelector, StringIndexerModel, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.stat import Correlation\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35ee10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Path to your dataset\n",
    "data_path = '/home/linuxu/Desktop/Submission/Student_Depression_Dataset.csv'\n",
    "\n",
    "# Load dataset into Spark DataFrame\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "# Display schema clearly to ensure correctness\n",
    "df.printSchema()\n",
    "\n",
    "# Show the first 5 rows clearly\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00cb645",
   "metadata": {},
   "source": [
    "# Remove Unwanted Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f9f0c",
   "metadata": {},
   "source": [
    "## Remove non student rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distinct professions before removal\n",
    "display(df.select(\"Profession\").distinct().toPandas())\n",
    "\n",
    "# Keep only rows where Profession is \"Student\"\n",
    "df_students = df.filter(df[\"Profession\"] == \"Student\")\n",
    "\n",
    "# Verify clearly that only students remain\n",
    "display(df_students.select(\"Profession\").distinct().toPandas())\n",
    "\n",
    "# Check new row count (should be smaller than before)\n",
    "print(f\"New row count after filtering students: {df_students.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7506e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "columns_to_remove = [\"Work Pressure\", \"Job Satisfaction\", \"Profession\"]  # remove \"Proffession\" as well, since it's now redundant (all are students)\n",
    "df_students_clean = df_students.drop(*columns_to_remove)\n",
    "\n",
    "# Verify clearly columns are removed\n",
    "df_students_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 5 rows to ensure dataset looks correct\n",
    "display(df_students_clean.limit(5).toPandas())\n",
    "\n",
    "# Show count for students with and without depression\n",
    "display(df.groupBy(\"Depression\").count().toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d00fb3",
   "metadata": {},
   "source": [
    "## Check and remove rows with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4858cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify missing values for cleanliness check\n",
    "missing_counts = df_students_clean.select([count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in df_students_clean.columns]).toPandas().T\n",
    "missing_counts.columns = [\"Missing Values\"]\n",
    "display(missing_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc8201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check rows with missing Financial Stress\n",
    "display(df_students_clean.filter(df_students_clean[\"Financial Stress\"].isNull()).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01098a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students_final = df_students_clean.na.drop(subset=[\"Financial Stress\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183f4d9",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a26cd",
   "metadata": {},
   "source": [
    "## Check basic statistics and categorical variables distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69522a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students_final.describe().toPandas().set_index(\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfafcfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_students_final.groupBy(\"Gender\").count().toPandas())\n",
    "display(df_students_final.groupBy(\"City\").count().toPandas())\n",
    "display(df_students_final.groupBy(\"Degree\").count().toPandas())\n",
    "display(df_students_final.groupBy(\"Sleep Duration\").count().toPandas())\n",
    "display(df_students_final.groupBy(\"Dietary Habits\").count().toPandas())\n",
    "display(df_students_final.groupBy(\"Family History of Mental Illness\").count().toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a79ee3",
   "metadata": {},
   "source": [
    "## Visualize numeric features correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af5b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\"Age\", \"Academic Pressure\", \"CGPA\", \"Study Satisfaction\", \"Work/Study Hours\", \"Financial Stress\", \"Depression\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"numeric_features\")\n",
    "df_vector = assembler.transform(df_students_final).select(\"numeric_features\")\n",
    "\n",
    "correlation_matrix = Correlation.corr(df_vector, \"numeric_features\").collect()[0][0]\n",
    "corr_array = correlation_matrix.toArray()\n",
    "\n",
    "# Creating readable Pandas DataFrame\n",
    "corr_df = pd.DataFrame(corr_array, index=numeric_cols, columns=numeric_cols)\n",
    "\n",
    "# Display clearly\n",
    "display(corr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8264a5f2",
   "metadata": {},
   "source": [
    "## Visualize depression by key categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540797a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(df_students_final.groupBy(\"Gender\", \"Depression\").count().toPandas())\n",
    "display(df_students_final.groupBy(\"City\", \"Depression\").count().toPandas())\n",
    "display(df_students_final.groupBy(\"Degree\", \"Depression\").count().toPandas())\n",
    "display(df_students_final.groupBy(\"Sleep Duration\", \"Depression\").count().toPandas())\n",
    "display(df_students_final.groupBy(\"Dietary Habits\", \"Depression\").count().toPandas())\n",
    "display(df_students_final.groupBy(\"Family History of Mental Illness\", \"Depression\").count().toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52268a42",
   "metadata": {},
   "source": [
    "## Create a correlation heatmap of numerical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas DataFrame\n",
    "corr_df = pd.DataFrame(correlation_matrix.toArray(), index=numeric_cols, columns=numeric_cols)\n",
    "\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_df, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4572baa6",
   "metadata": {},
   "source": [
    "## Remove rows with typos in \"city\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rare cities (e.g., less than 5 occurrences)\n",
    "city_counts = df_students_final.groupBy(\"City\").count()\n",
    "rare_cities = city_counts.filter(\"count < 5\").select(\"City\").collect()\n",
    "rare_city_list = [row['City'] for row in rare_cities]\n",
    "\n",
    "# Remove rows with rare cities\n",
    "df_students_final = df_students_final.filter(~col(\"City\").isin(rare_city_list))\n",
    "\n",
    "display(df_students_final.groupBy(\"City\").count().toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e584b",
   "metadata": {},
   "source": [
    "# Encoding Categorical Features - Feature Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c3259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary and Ordinal columns clearly indexed\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=\"Gender\", outputCol=\"GenderIdx\"),\n",
    "    StringIndexer(inputCol=\"Family History of Mental Illness\", outputCol=\"FamilyHistoryIdx\",stringOrderType=\"alphabetAsc\"),\n",
    "    StringIndexer(inputCol=\"Have you ever had suicidal thoughts ?\", outputCol=\"SuicidalThoughtsIdx\",stringOrderType=\"alphabetAsc\"),\n",
    "    StringIndexer(inputCol=\"Sleep Duration\", outputCol=\"SleepDurationIdx\"),\n",
    "    StringIndexer(inputCol=\"Dietary Habits\", outputCol=\"DietaryHabitsIdx\")\n",
    "]\n",
    "\n",
    "# Nominal columns indexed then One-Hot encoded clearly\n",
    "indexers += [\n",
    "    StringIndexer(inputCol=\"City\", outputCol=\"CityIdx\"),\n",
    "    StringIndexer(inputCol=\"Degree\", outputCol=\"DegreeIdx\")\n",
    "]\n",
    "\n",
    "encoders = [\n",
    "    OneHotEncoder(inputCol=\"CityIdx\", outputCol=\"CityVec\"),\n",
    "    OneHotEncoder(inputCol=\"DegreeIdx\", outputCol=\"DegreeVec\")\n",
    "]\n",
    "\n",
    "# Set up and run the pipeline clearly\n",
    "pipeline = Pipeline(stages=indexers + encoders)\n",
    "pipeline_model = pipeline.fit(df_students_final)\n",
    "df_encoded = pipeline_model.transform(df_students_final)\n",
    "\n",
    "\n",
    "# Verify clearly that encoding was successful\n",
    "df_encoded.select(\n",
    "    \"Gender\", \"GenderIdx\", \n",
    "    \"Family History of Mental Illness\", \"FamilyHistoryIdx\",\n",
    "    \"Have you ever had suicidal thoughts ?\", \"SuicidalThoughtsIdx\",\n",
    "    \"Sleep Duration\", \"SleepDurationIdx\",\n",
    "    \"Dietary Habits\", \"DietaryHabitsIdx\",\n",
    "    \"City\", \"CityVec\",\n",
    "    \"Degree\", \"DegreeVec\"\n",
    ").limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f807b4c",
   "metadata": {},
   "source": [
    "## Create a correlation heatmap of all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa7954f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# List of all numeric and encoded categorical columns\n",
    "heatmap_cols = [\n",
    "    \"Age\",\n",
    "    \"Academic Pressure\",\n",
    "    \"CGPA\",\n",
    "    \"Study Satisfaction\",\n",
    "    \"Work/Study Hours\",\n",
    "    \"Financial Stress\",\n",
    "    \"GenderIdx\",\n",
    "    \"FamilyHistoryIdx\",\n",
    "    \"SuicidalThoughtsIdx\",\n",
    "    \"SleepDurationIdx\",\n",
    "    \"DietaryHabitsIdx\",\n",
    "    \"CityIdx\",\n",
    "    \"DegreeIdx\",\n",
    "    \"Depression\"\n",
    "]\n",
    "\n",
    "# Assemble these columns into a vector\n",
    "assembler = VectorAssembler(inputCols=heatmap_cols, outputCol=\"heatmap_features\")\n",
    "df_heatmap_vector = assembler.transform(df_encoded).select(\"heatmap_features\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = Correlation.corr(df_heatmap_vector, \"heatmap_features\").collect()[0][0]\n",
    "\n",
    "# Convert to Pandas DataFrame for visualization\n",
    "corr_df = pd.DataFrame(corr_matrix.toArray(), index=heatmap_cols, columns=heatmap_cols)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_df, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Comprehensive Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b065e1a",
   "metadata": {},
   "source": [
    "# Feature Selection and Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a87f36",
   "metadata": {},
   "source": [
    "## Final feature preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49607b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"Age\", \"Academic Pressure\", \"CGPA\", \"Study Satisfaction\",\n",
    "    \"Work/Study Hours\", \"Financial Stress\", \"GenderIdx\", \n",
    "    \"FamilyHistoryIdx\", \"SuicidalThoughtsIdx\", \"SleepDurationIdx\", \n",
    "    \"DietaryHabitsIdx\", \"CityVec\", \"DegreeVec\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df_final = assembler.transform(df_encoded).select(\"features\", \"Depression\")\n",
    "\n",
    "df_final.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31589de",
   "metadata": {},
   "source": [
    "## Splitting data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ce257",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, test_data) = df_final.randomSplit([0.8, 0.2], seed=42)\n",
    "print(\"Training set count:\", train_data.count())\n",
    "print(\"Test set count:\", test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e640396",
   "metadata": {},
   "source": [
    "## Training a logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Depression\")\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Display model coefficients and intercept\n",
    "print(\"Coefficients:\", lr_model.coefficients)\n",
    "print(\"Intercept:\", lr_model.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8605f",
   "metadata": {},
   "source": [
    "## Evaluating the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a035b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Binary evaluation for Accuracy and AUC\n",
    "binary_evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Depression\")\n",
    "auc = binary_evaluator.evaluate(predictions, {binary_evaluator.metricName: \"areaUnderROC\"})\n",
    "accuracy = predictions.filter(predictions.Depression == predictions.prediction).count() / predictions.count()\n",
    "\n",
    "# Multiclass evaluators for precision and recall\n",
    "precision_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Depression\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Depression\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "\n",
    "# Calculate precision and recall for class '1' (Depression positive)\n",
    "precision = precision_evaluator.evaluate(predictions, {precision_evaluator.metricLabel: 1.0})\n",
    "recall = recall_evaluator.evaluate(predictions, {recall_evaluator.metricLabel: 1.0})\n",
    "\n",
    "# Display all metrics clearly\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Precision (Depression=1): {precision:.2f}\")\n",
    "print(f\"Recall (Depression=1): {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e375e",
   "metadata": {},
   "source": [
    "# Part 2 - Influential Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d3700",
   "metadata": {},
   "source": [
    "## Chi-square feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square selector to select top 12 features\n",
    "selector = ChiSqSelector(numTopFeatures=12, featuresCol=\"features\", labelCol=\"Depression\", outputCol=\"selectedFeatures\")\n",
    "\n",
    "# Fit selector to training data\n",
    "selector_model = selector.fit(train_data)\n",
    "\n",
    "# Transform train and test datasets\n",
    "train_selected = selector_model.transform(train_data).select(\"selectedFeatures\", \"Depression\")\n",
    "test_selected = selector_model.transform(test_data).select(\"selectedFeatures\", \"Depression\")\n",
    "\n",
    "# Display the selected features from training set\n",
    "train_selected.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c0540",
   "metadata": {},
   "source": [
    "## Retrain and evaluate model on selected features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9de5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain logistic regression model with selected features\n",
    "lr_selected = LogisticRegression(featuresCol=\"selectedFeatures\", labelCol=\"Depression\")\n",
    "lr_selected_model = lr_selected.fit(train_selected)\n",
    "\n",
    "# Evaluate again\n",
    "predictions_selected = lr_selected_model.transform(test_selected)\n",
    "\n",
    "# Binary evaluation for Accuracy and AUC\n",
    "binary_evaluator_2 = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Depression\")\n",
    "auc_2 = binary_evaluator_2.evaluate(predictions_selected, {binary_evaluator_2.metricName: \"areaUnderROC\"})\n",
    "accuracy_2 = predictions_selected.filter(predictions_selected.Depression == predictions_selected.prediction).count() / predictions_selected.count()\n",
    "\n",
    "# Multiclass evaluators for precision and recall\n",
    "precision_evaluator_2 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Depression\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "recall_evaluator_2 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Depression\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "\n",
    "# Calculate precision and recall for class '1' (Depression positive)\n",
    "precision_2 = precision_evaluator_2.evaluate(predictions_selected, {precision_evaluator_2.metricLabel: 1.0})\n",
    "recall_2 = recall_evaluator_2.evaluate(predictions_selected, {recall_evaluator_2.metricLabel: 1.0})\n",
    "\n",
    "# Display all metrics clearly\n",
    "print(f\"Accuracy: {accuracy_2:.2f}\")\n",
    "print(f\"AUC: {auc_2:.2f}\")\n",
    "print(f\"Precision (Depression=1): {precision_2:.2f}\")\n",
    "print(f\"Recall (Depression=1): {recall_2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35788625",
   "metadata": {},
   "source": [
    "Precision got better by 0.01 when selected the top 12 features using Chi-square feature selection!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f59cfa3",
   "metadata": {},
   "source": [
    "## Extract actual feature names from chi-square selector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa902f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sizes of One-Hot Encoded vectors\n",
    "city_vec_size = df_encoded.select(\"CityVec\").first()[\"CityVec\"].size\n",
    "degree_vec_size = df_encoded.select(\"DegreeVec\").first()[\"DegreeVec\"].size\n",
    "\n",
    "# Reconstruct full feature names in correct order (as used in original assembler)\n",
    "full_feature_names = (\n",
    "    [\"Age\", \"Academic Pressure\", \"CGPA\", \"Study Satisfaction\",\n",
    "     \"Work/Study Hours\", \"Financial Stress\", \"GenderIdx\",\n",
    "     \"FamilyHistoryIdx\", \"SuicidalThoughtsIdx\", \"SleepDurationIdx\", \"DietaryHabitsIdx\"]\n",
    "    + [f\"CityVec_{i}\" for i in range(city_vec_size)]\n",
    "    + [f\"DegreeVec_{i}\" for i in range(degree_vec_size)]\n",
    ")\n",
    "\n",
    "# Get selected feature indices from Chi-Square\n",
    "selected_feature_indices = selector_model.selectedFeatures\n",
    "\n",
    "# Load label mappings for City and Degree\n",
    "fitted_stages = pipeline.fit(df_students_final).stages\n",
    "city_indexer_model = [stage for stage in fitted_stages if isinstance(stage, StringIndexerModel) and stage.getInputCol() == \"City\"][0]\n",
    "degree_indexer_model = [stage for stage in fitted_stages if isinstance(stage, StringIndexerModel) and stage.getInputCol() == \"Degree\"][0]\n",
    "city_labels = city_indexer_model.labels\n",
    "degree_labels = degree_indexer_model.labels\n",
    "\n",
    "# Map feature names\n",
    "selected_feature_names = []\n",
    "pretty_feature_names = []\n",
    "\n",
    "for idx in selected_feature_indices:\n",
    "    raw_name = full_feature_names[idx]\n",
    "    selected_feature_names.append(raw_name)\n",
    "\n",
    "    if raw_name.startswith(\"CityVec_\"):\n",
    "        i = int(raw_name.split(\"_\")[1])\n",
    "        city = city_labels[i] if i < len(city_labels) else \"Unknown\"\n",
    "        pretty_feature_names.append(f\"{raw_name} ({city})\")\n",
    "    elif raw_name.startswith(\"DegreeVec_\"):\n",
    "        i = int(raw_name.split(\"_\")[1])\n",
    "        degree = degree_labels[i] if i < len(degree_labels) else \"Unknown\"\n",
    "        pretty_feature_names.append(f\"{raw_name} ({degree})\")\n",
    "    else:\n",
    "        pretty_feature_names.append(raw_name)\n",
    "\n",
    "print(\"Selected Features:\", pretty_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0df764",
   "metadata": {},
   "source": [
    "## Map coefficients to selected features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba8517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = lr_selected_model.coefficients.toArray()\n",
    "\n",
    "# Create DataFrame showing importance\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": pretty_feature_names,\n",
    "    \"Coefficient\": coefficients,\n",
    "    \"Abs_Coefficient\": abs(coefficients)\n",
    "}).sort_values(by=\"Abs_Coefficient\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Rank the features properly\n",
    "feature_importance_df.index = feature_importance_df.index + 1  # Start from 1\n",
    "\n",
    "display(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538062cf",
   "metadata": {},
   "source": [
    "## Classify features (behavioral vs. demographic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de68f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize classification for selected features\n",
    "behavioral_keywords = [\n",
    "    \"Academic Pressure\", \"CGPA\", \"Study Satisfaction\", \"Work/Study Hours\",\n",
    "    \"SuicidalThoughtsIdx\", \"SleepDurationIdx\", \"DietaryHabitsIdx\"\n",
    "]\n",
    "\n",
    "def classify_feature(f):\n",
    "    return \"Behavioral\" if any(b in f for b in behavioral_keywords) else \"Demographic\"\n",
    "\n",
    "feature_importance_df[\"Category\"] = feature_importance_df[\"Feature\"].apply(classify_feature)\n",
    "\n",
    "display(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b91bb0",
   "metadata": {},
   "source": [
    "## Visualize influential features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc21a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    data=feature_importance_df,\n",
    "    x=\"Abs_Coefficient\",\n",
    "    y=\"Feature\",\n",
    "    hue=\"Category\",\n",
    "    dodge=False\n",
    ")\n",
    "\n",
    "plt.title(\"Top 12 Influential Features by Logistic Regression Coefficient\")\n",
    "plt.xlabel(\"Absolute Coefficient Value\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.legend(title=\"Feature Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a56d9",
   "metadata": {},
   "source": [
    "# Part 2 Summary - Identifying and Classifying Influential Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8a39b9",
   "metadata": {},
   "source": [
    "### In this stage, we aimed to determine which features contribute most significantly to predicting student depression, using the trained logistic regression model and Spark ML tools studied in class.\n",
    "\n",
    "\n",
    "#### 1. Feature Selection:\n",
    "\n",
    "We applied Chi-Square feature selection on the training data and selected the top 12 most predictive features. \n",
    "These included a mix of numerical, indexed categorical, and one-hot encoded variables.\n",
    "\n",
    "\n",
    "#### 2. Feature Importance Analysis:\n",
    "\n",
    "Using the coefficients from the retrained logistic regression model, we ranked the selected features based on the absolute value of their coefficients, which represent their impact on the prediction.\n",
    "\n",
    "\n",
    "#### 3. Behavioral vs. Demographic Classification:\n",
    "\n",
    "We grouped the influential features into:\n",
    " - Behavioral Factors: e.g., Suicidal Thoughts, Academic Pressure, Dietary Habits, etc.\n",
    " - Demographic Factors: e.g., Age, Financial Stress, City, Degree.\n",
    "\n",
    "\n",
    "#### 4. Key Findings:\n",
    "\n",
    "- Most influential feature: \"SuicidalThoughtsIdx\" had the highest coefficient, indicating a strong correlation with depression.\n",
    " \n",
    "- Other highly impactful features included Academic Pressure, Financial Stress, and Dietary Habits.\n",
    " \n",
    "- Both behavioral and demographic factors contribute meaningfully, but behavioral features generally had higher absolute coefficients, highlighting their critical role in depression prediction.\n",
    " \n",
    "- Notably, CityVec_2 (Hyderabad) and DegreeVec_0 (Class 12) were the most influential one-hot encoded demographic attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd6530f",
   "metadata": {},
   "source": [
    "# Part 3 - Real-Time Depression Prediction Using Kafka & Spark Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91200eb7",
   "metadata": {},
   "source": [
    "## Spark Consumer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de216e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop previous streaming query if exists\n",
    "try:\n",
    "    query.stop()\n",
    "    print(\"Stopped previous query.\")\n",
    "except NameError:\n",
    "    print(\"No active query to stop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de02b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Define the schema for incoming student JSON data\n",
    "student_schema = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"Gender\", StringType()),\n",
    "    StructField(\"Age\", DoubleType()),\n",
    "    StructField(\"City\", StringType()),\n",
    "    StructField(\"Academic Pressure\", DoubleType()),\n",
    "    StructField(\"CGPA\", DoubleType()),\n",
    "    StructField(\"Study Satisfaction\", DoubleType()),\n",
    "    StructField(\"Sleep Duration\", StringType()),\n",
    "    StructField(\"Dietary Habits\", StringType()),\n",
    "    StructField(\"Degree\", StringType()),\n",
    "    StructField(\"Have you ever had suicidal thoughts ?\", StringType()),\n",
    "    StructField(\"Work/Study Hours\", DoubleType()),\n",
    "    StructField(\"Financial Stress\", DoubleType()),\n",
    "    StructField(\"Family History of Mental Illness\", StringType()),\n",
    "    StructField(\"Depression\", IntegerType())\n",
    "])\n",
    "\n",
    "# Step 1: Read from Kafka\n",
    "raw_kafka_df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"depression-stream\") \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "# Step 2: Parse the JSON\n",
    "json_df = raw_kafka_df.selectExpr(\"CAST(value AS STRING) as json_string\") \\\n",
    "    .select(from_json(col(\"json_string\"), student_schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\") \\\n",
    "    .dropDuplicates([\"id\"])\n",
    "\n",
    "# Step 3: Apply preprocessing pipeline\n",
    "preprocessed_df = pipeline_model.transform(json_df)\n",
    "\n",
    "# Step 4: Assemble the features\n",
    "feature_cols = [\n",
    "    \"Age\", \"Academic Pressure\", \"CGPA\", \"Study Satisfaction\",\n",
    "    \"Work/Study Hours\", \"Financial Stress\", \"GenderIdx\", \n",
    "    \"FamilyHistoryIdx\", \"SuicidalThoughtsIdx\", \"SleepDurationIdx\", \n",
    "    \"DietaryHabitsIdx\", \"CityVec\", \"DegreeVec\"\n",
    "]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "features_df = assembler.transform(preprocessed_df)\n",
    "\n",
    "# Step 5: Select top features and predict\n",
    "selected_df = selector_model.transform(features_df) \\\n",
    "    .select(\"selectedFeatures\", \"Depression\", \"id\", \"Gender\", \"City\")\n",
    "predictions_df = lr_selected_model.transform(selected_df)\n",
    "\n",
    "# Step 6: Output predictions to console\n",
    "query = predictions_df.select(\n",
    "    col(\"id\"),\n",
    "    col(\"Gender\"),\n",
    "    col(\"City\"),\n",
    "    col(\"Depression\").alias(\"Actual\"),\n",
    "    col(\"prediction\").alias(\"Predicted\")\n",
    ").writeStream \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", False) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525bf41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
